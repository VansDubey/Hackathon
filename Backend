import tkinter as tk
from tkinter import messagebox
import requests
from bs4 import BeautifulSoup
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk import ne_chunk, pos_tag
from collections import defaultdict

nltk.download('punkt')
nltk.download('maxent_ne_chunker')
nltk.download('words')
nltk.download('averaged_perceptron_tagger')

def scrape_website(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Ensure we notice bad responses
        soup = BeautifulSoup(response.content, 'html.parser')
        page_text = soup.get_text(separator=' ')
        return page_text
    except requests.RequestException as e:
        messagebox.showerror("Error", f"An error occurred: {e}")
        return ""

def identify_entities(text):
    sentences = sent_tokenize(text)
    entities = defaultdict(list)
    for sentence in sentences:
        words = word_tokenize(sentence)
        pos_tags = pos_tag(words)
        chunked = ne_chunk(pos_tags, binary=False)
        for subtree in chunked:
            if hasattr(subtree, 'label'):
                entity_name = " ".join([leaf[0] for leaf in subtree.leaves()])
                entity_type = subtree.label()
                entities[entity_name].append((entity_type, sentence))
    return entities

def generate_questions(text, num_questions=10):
    entities = identify_entities(text)
    questions = []

    if not entities:
        return [("No significant entities found to generate questions.", "Please try another webpage.")]
    
    # Generate unique questions
    used_entities = set()
    for entity, contexts in entities.items():
        if len(questions) >= num_questions:
            break

        if entity in used_entities:
            continue
        used_entities.add(entity)

        if not contexts:
            continue
        
        entity_type, _ = contexts[0]  # Get the entity type from the first context

        if entity_type == "PERSON":
            question = f"Who is {entity}?"
        elif entity_type == "ORGANIZATION":
            question = f"What is {entity}?"
        elif entity_type == "GPE":
            question = f"Where is {entity} located?"
        elif entity_type == "DATE":
            question = f"What happened on {entity}?"
        elif entity_type == "MONEY":
            question = f"How much money is associated with {entity}?"
        else:
            question = f"What is {entity}?"
        
        # Extract relevant sentences
        relevant_sentences = [sentence for _, sentence in contexts]
        if not relevant_sentences:
            answer = "No specific information found."
        else:
            answer = " ".join(relevant_sentences[:2])  # Join up to 2 sentences for context
            answer = answer[:80] + "..." if len(answer) > 80 else answer
        
        questions.append((question, answer))
    
    return questions

def create_chatbot_output(url):
    text_content = scrape_website(url)
    if text_content:
        questions = generate_questions(text_content)
        return questions
    return []

def display_questions(questions):
    questions_window = tk.Toplevel(root)
    questions_window.title("Generated Questions")
    questions_window.geometry("600x400")
    
    canvas = tk.Canvas(questions_window)
    scrollbar = tk.Scrollbar(questions_window, orient="vertical", command=canvas.yview)
    
    questions_frame = tk.Frame(canvas)
    questions_frame.bind("<Configure>", lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
    
    canvas.create_window((0, 0), window=questions_frame, anchor="nw")
    canvas.pack(side="left", fill="both", expand=True)
    scrollbar.pack(side="right", fill="y")
    
    canvas.config(yscrollcommand=scrollbar.set)
    
    for i, (question, answer) in enumerate(questions):
        tk.Label(questions_frame, text=f"Q{i+1}: {question}", wraplength=550, justify="left").pack(anchor="w", padx=10, pady=5)
        tk.Label(questions_frame, text=f"A{i+1}: {answer}", wraplength=550, justify="left").pack(anchor="w", padx=10, pady=5)
        tk.Label(questions_frame, text="").pack()
    
def process_url():
    url = url_entry.get()
    if not url:
        messagebox.showwarning("Input Error", "Please enter a valid URL.")
        return
    
    questions = create_chatbot_output(url)
    if not questions:
        messagebox.showwarning("No Content", "No questions could be generated from the provided URL.")
    else:
        display_questions(questions)

root = tk.Tk()
root.title("Website Scraper and Question Generator")
root.geometry("400x200")

tk.Label(root, text="Enter the URL of the website:").pack(pady=10)
url_entry = tk.Entry(root, width=50)
url_entry.pack(pady=5)

submit_button = tk.Button(root, text="Generate Questions", command=process_url)
submit_button.pack(pady=20)

root.mainloop()